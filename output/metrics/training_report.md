
# Raport Treningu Modelu

## Informacje Podstawowe
- **Data treningu**: 2025-10-05 12:53:56
- **Model**: microsoft/DialoGPT-small
- **Epoki**: 1.0
- **Łączne kroki**: 2
- **Czas treningu**: 0.00 sekund

## Metryki Treningu
- **Final Train Loss**: 0.000000
- **Best Eval Loss**: inf
- **FLOPS**: 2148318314496.0

## Konfiguracja Treningu
- **Learning Rate**: 5e-05
- **Batch Size**: 2
- **Gradient Accumulation Steps**: 4
- **Max Length**: 256

## LoRA Konfiguracja
- **Włączone**: True
- **Rank (r)**: 16
- **Alpha**: 32
- **Dropout**: 0.1

## Historia Treningu

## Wnioski
- **Wynik**: Niski final loss - model dobrze się uczył
